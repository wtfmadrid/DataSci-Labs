{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In SVM, what is the meaning of margin?\n",
    "\n",
    "With regards to Support Vector Machines, margin is the distance between the hyperplane/line and the closest input data points. The hyperplane is a line that separates the input data by class.\n",
    "\n",
    "#### What are the equations of the two margin hyperplanes H+ and H- ?\n",
    "\n",
    "Given that the equation of our Maximal-Margin hyperplane is W<sup>T</sup>X + b = 0 where W<sup>T</sup> is a vector normal to the hyperplane, b is an offset and X is our set of input points, the equations of the two margin hyperplanes H+ and H- are:<br>\n",
    "f(X)=W<sup>T</sup>X + b = 1 and g(X)=W<sup>T</sup>X + b = -1 respectively.\n",
    "\n",
    "#### Consider the three linearly separable two-dimensional input vectors in the following figure. Find the linear SVM that optimally separates the classes by maximizing the margin.\n",
    "\n",
    "f(X) = W<sup>T</sup>X + b = w1x1 + w2x2 + b = 0\n",
    "\n",
    "Rearranging the equation we get: <br>\n",
    "\n",
    "x2 = -(w1/w2)x1 - (b/w2)<br>\n",
    "\n",
    "w1/w2 is the slope connecting points x1=(2, 0) and x2=(0, 2)<br>\n",
    "\n",
    "w1/w2 = (2 - 0)/(0 - 2) = -1/1 <br>\n",
    "\n",
    "From w1x1 + w2x2 + b = 0 we rearrange and solve for b using point (2, 0):<br>\n",
    "\n",
    "b = -(w1x1)-(w2x2) = -(-1)(2) - (1)(0) = 2 <br>\n",
    "\n",
    "Finally, our hyperplane can be given by the following equation: <br>\n",
    "\n",
    "f(X) = -X + 2 = 0<br>\n",
    "\n",
    "Therefore, the linear SVM that optimally separates the classes is f(X) = -X + 2 = 0\n",
    "\n",
    "#### What is a kernel function?\n",
    "\n",
    "The kernel function is a fundamental component of the implementation of Support Vector Machines. Support Vector Machines can be rephrased/transformed using the inner product of the input data. The inner product is the sum of the product of each pair of input values. In essence, the dot product is considered the kernel and can be written as the following:<br>\n",
    "\n",
    "K(x, xi) = sum(x * Xi)\n",
    "\n",
    "The kernel defines the distance between a new input data point and the support vectors.\n",
    "\n",
    "Kernel functions can be used to map input data to higher dimensions where the data can be better separated in cases where the data cannot be separated in lower dimensions. This is known as the kernel trick. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of SVM and Multi-Layer Perceptron Models Without Pre-Processing\n",
    "\n",
    "The following results were obtained without any pre-processing of the Heart Disease Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM linear % 60.0\n",
      "Accuracy of SVM poly % 56.667\n",
      "Accuracy of SVM rbf % 51.667\n",
      "Accuracy of SVM sigmoid % 51.667\n",
      "\n",
      "Accuracy of MLP  sgd % 16.667\n",
      "Accuracy of MLP  adam % 56.667\n",
      "\n",
      "The highest accuracy is % 60.0 which corresponds to the Linear SVM Model\n",
      "The average accuracy of SVM is % 55.0\n",
      "The average accuracy of MLP is % 36.667\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('heart-disease-dataset1.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.dropna()\n",
    "\n",
    "X = data.drop('result', axis = 1)\n",
    "Y = data['result']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, random_state=3, test_size=0.2)\n",
    "svmkernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for n in svmkernel:\n",
    "    sm = svm.SVC(kernel=n, random_state=1, gamma='auto')\n",
    "    sm = sm.fit(xtrain, ytrain)\n",
    "    ypred = sm.predict(xtest)\n",
    "    accuracy = round(sm.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of SVM', n, '%', accuracy)\n",
    "\n",
    "mlp_descent = ['sgd', 'adam']\n",
    "print()\n",
    "\n",
    "for k in mlp_descent:\n",
    "    clf = MLPClassifier(solver=k, alpha=1e-5, hidden_layer_sizes=(1, ),\\\n",
    "                    random_state=1, max_iter=10000, activation='identity', learning_rate_init=0.01)\n",
    "\n",
    "    clf = clf.fit(xtrain, ytrain)\n",
    "    accuracy = round(clf.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of MLP ', k, '%', accuracy)\n",
    "\n",
    "print()\n",
    "print('The highest accuracy is %', max(accuracy_list), 'which corresponds to the Linear SVM Model')\n",
    "print('The average accuracy of SVM is %', round(np.mean(accuracy_list[0:4]), 3))\n",
    "print('The average accuracy of MLP is %', round(np.mean(accuracy_list[4:6]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of SVM and Multi-Layer Perceptron Models With Pre-Processing Using Data Scaling\n",
    "\n",
    "Scaling is a common pre-processing technique which standardizes the data using statistical methods. Some models such as SVMs and Multi-Layer Perceptrons may perform better when the input data is standardized. This is why we have chosen to include this iteration of the SVM and MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM linear % 63.333\n",
      "Accuracy of SVM poly % 56.667\n",
      "Accuracy of SVM rbf % 60.0\n",
      "Accuracy of SVM sigmoid % 56.667\n",
      "\n",
      "Accuracy of MLP  sgd % 56.667\n",
      "Accuracy of MLP  adam % 60.0\n",
      "\n",
      "The highest accuracy is % 63.333 which corresponds to the Linear SVM Model\n",
      "The average accuracy of SVM is % 59.167\n",
      "The average accuracy of MLP is % 58.334\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('heart-disease-dataset1.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.dropna()\n",
    "\n",
    "attributes = data.drop('result', axis = 1)\n",
    "target = data['result']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(attributes)\n",
    "attr_scaled = scaler.transform(attributes) \n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(attr_scaled, target, random_state=3, test_size=0.2)\n",
    "svmkernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for n in svmkernel:\n",
    "    sm = svm.SVC(kernel=n, random_state=1, gamma='auto')\n",
    "    sm = sm.fit(xtrain, ytrain)\n",
    "    ypred = sm.predict(xtest)\n",
    "    accuracy = round(sm.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of SVM', n, '%', accuracy)\n",
    "\n",
    "mlp_descent = ['sgd', 'adam']\n",
    "print()\n",
    "\n",
    "for k in mlp_descent:\n",
    "    clf = MLPClassifier(solver=k, alpha=1e-5, hidden_layer_sizes=(1, ),\\\n",
    "                    random_state=1, max_iter=10000, activation='identity', learning_rate_init=0.01)\n",
    "\n",
    "    clf = clf.fit(xtrain, ytrain)\n",
    "    accuracy = round(clf.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of MLP ', k, '%', accuracy)\n",
    "\n",
    "print()\n",
    "print('The highest accuracy is %', max(accuracy_list), 'which corresponds to the Linear SVM Model')\n",
    "print('The average accuracy of SVM is %', round(np.mean(accuracy_list[0:4]), 3))\n",
    "print('The average accuracy of MLP is %', round(np.mean(accuracy_list[4:6]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of SVM and Multi-Layer Perceptron Models With Pre-Processing By Binarizing the Result Attribute\n",
    "\n",
    "Since the result attribute is given by an integer ranging from 0 to 4, and both SVM and Multi-Layer Perceptron work better with binary classification, we decided to see how what results we would get by binarizing the result attribute. In this case, 1 would indicate the existence of heart disease and 0 would indicate no heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM linear % 85.0\n",
      "Accuracy of SVM poly % 81.667\n",
      "Accuracy of SVM rbf % 51.667\n",
      "Accuracy of SVM sigmoid % 51.667\n",
      "\n",
      "Accuracy of MLP  sgd % 48.333\n",
      "Accuracy of MLP  adam % 48.333\n",
      "\n",
      "The highest accuracy is % 85.0 which corresponds to the Linear SVM Model\n",
      "The average accuracy of SVM is % 67.5\n",
      "The average accuracy of MLP is % 48.333\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('heart-disease-dataset1.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.dropna()\n",
    "\n",
    "attributes = data.drop('result', axis = 1)\n",
    "target = [i if i==0 else 1 for i in data['result']]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(attributes, target, random_state=3, test_size=0.2)\n",
    "svmkernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for n in svmkernel:\n",
    "    sm = svm.SVC(kernel=n, random_state=1, gamma='auto')\n",
    "    sm = sm.fit(xtrain, ytrain)\n",
    "    ypred = sm.predict(xtest)\n",
    "    accuracy = round(sm.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of SVM', n, '%', accuracy)\n",
    "\n",
    "mlp_descent = ['sgd', 'adam']\n",
    "print()\n",
    "\n",
    "for k in mlp_descent:\n",
    "    clf = MLPClassifier(solver=k, alpha=1e-5, hidden_layer_sizes=(1, ),\\\n",
    "                    random_state=1, max_iter=10000, activation='identity', learning_rate_init=0.01)\n",
    "\n",
    "    clf = clf.fit(xtrain, ytrain)\n",
    "    accuracy = round(clf.score(xtest, ytest) * 100, 3)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy of MLP ', k, '%', accuracy)\n",
    "\n",
    "print()\n",
    "print('The highest accuracy is %', max(accuracy_list), 'which corresponds to the Linear SVM Model')\n",
    "print('The average accuracy of SVM is %', round(np.mean(accuracy_list[0:4]), 3))\n",
    "print('The average accuracy of MLP is %', round(np.mean(accuracy_list[4:6]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the SVM models performed better since they had higher accuracy scores. Regardless of whether pre-processing was performed on the data, and regardless of the type of pre-processing, the SVM models had higher accuracy scores. Among the SVM models, the model which utilized the linear kernel performed the best and resulted in the highest accuracy scores across all iterations of model building. Therefore, the highest performing model is the Linear SVM model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
